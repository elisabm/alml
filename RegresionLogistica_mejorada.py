# -*- coding: utf-8 -*-
"""Regresión_logistica.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17ae_fiNMJ2dpbnzGZjOI-W8iXTtBQ3DZ

Librerias
"""

import numpy as np

"""regresion logistica"""

import numpy as np

class RegLogistica():

  
  #Declararemos el número de iteraciones y el learning rate
  def __init__(self, learning_rate, num_i):

    self.learning_rate = learning_rate
    self.num_i = num_i

  #Crearemos una función para entrenar el modelo
  def fit(self, X, Y):
    

    #Lo siguiente nos regresa la forma de la base de datos
    #m --> cuantas lineas de datos hay (filas) --> nos va a servir a la hora de derivar
    #n --> cuantos features tiene la base de datos (columnas) --> nos sirve para saber cuantos pesos necesitamos
    self.m, self.n = X.shape

    #Iniciamos los valores weight y bias

    self.w = np.zeros(self.n)
    self.b = 0
    self.X = X
    self.Y = Y

    #Usamos Gradient Descent para optimizar

    for i in range(self.num_i):
      self.weights_new()



  def weights_new(self):

    #Función Sigmoide  

    z = self.X.dot(self.w) + self.b

    fun_s = 1 / (1 + np.exp(-(z)))

    #Es la fórmula --> w*X + b
    

    #Derivadas (fórmulas)

    dw =(1/self.m)*np.dot(self.X.T, (fun_s - self.Y)) #Usamos T para poder multiplicar las matrices 

    db= (1/self.m)*np.sum(fun_s - self.Y)

    #Actualizamos weights y bias 

    self.w =self.w -self.learning_rate * dw

    self.b = self.b - self.learning_rate * db



  def pred(self,X):

    #La función sigmoide devuelve la probabilidad del valor que esta prediciendo
    #A nosotros nos interesa saber el valor como tal por lo que haremos lo siguiente
    z = X.dot(self.w) + self.b
    Y_pred = 1 / (1 + np.exp(-(z))) 
    

    Y_pred = np.where(Y_pred > 0.5,1,0)

    return Y_pred

import pandas as pd
from sklearn.preprocessing import StandardScaler

from sklearn.metrics import accuracy_score

url = 'https://raw.githubusercontent.com/elisabm/alml/main/diabetes2.csv'

data= pd.read_csv(url,index_col=0).drop_duplicates()

data.head()

data.shape

data.describe()

data["Outcome"].value_counts()

data.groupby('Outcome').mean()

feat =data.drop(columns ='Outcome', axis=1)
target =data['Outcome']

#Estandarizar datos 
scaler =StandardScaler()

scaler.fit(feat)

standardized_data= scaler.transform(feat)

#Separamos el data set
import math

s_f = 0.7 # 70% de los datos

n_train = math.floor(s_f * feat.shape[0])
n_test = math.ceil((1-s_f) * feat.shape[0])
X_train = feat[:n_train]
y_train = target[:n_train]
X_test = feat[n_train:]
y_test = target[n_train:]


print("Total Number of rows in train:",X_train.shape[0])
print("Total Number of rows in test:",X_test.shape[0])
print(y_test.shape)
print(X_test.shape)

#Creamos nuestro modelo y lo entrenamos 

modelo1 = RegLogistica(learning_rate= 0.01, num_i=1000)
modelo1.fit(X_train, y_train)

X_train_pred = modelo1.pred(X_train)
#checamos el accuracy

acc = np.sum(np.equal(X_train_pred, y_train)) / len(y_train)

print(acc)

#Con estos parámetros se obtuvo un accuracy de 0.6480446927374302

#Hacemos predicciones
print(X_test.shape)

X_test_pred = modelo1.pred(X_test)

print(X_test_pred.shape)

acc = np.sum(np.equal(X_test_pred, y_test)) / len(y_test)

print(acc)

#Y con el mismo modelo se hizo una prueba y el accuracy fue de 0.658008658008658

#Se crea una función que prueba los diferentes learning rates

learning_rates = [0.1, 0.15, 0.5, 0.04]
models = {}

for i in learning_rates:
    print ("learning rate es: ",i)
    models[i+1] = RegLogistica(learning_rate = i, num_i=1000) 
    models[i+1].fit(X_train, y_train)
    X_train_pred = models[i+1].pred(X_train)
    acc = np.sum(np.equal(X_train_pred, y_train)) / len(y_train)
    print("El accuracy es: ",acc)
    print ("-------------------------------------------------------")

'''Se obtuvo que  para
learning rate es:  0.1
El accuracy es:  0.6685288640595903
-------------------------------------------------------
learning rate es:  0.15
El accuracy es:  0.6741154562383612
-------------------------------------------------------
learning rate es:  0.5
El accuracy es:  0.6536312849162011
-------------------------------------------------------
learning rate es:  0.04
El accuracy es:  0.6480446927374302
-------------------------------------------------------
 '''

 #Podemos ver que para este problema no se debe de usar un learning rate tan bajo